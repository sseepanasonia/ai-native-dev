# Demo 07: LangChain MCP Integration ğŸ”—

Learn how to integrate MCP tools with LangChain agents to build powerful AI workflows.

## ğŸ¯ What You'll Learn

- Converting MCP tools to LangChain tools
- Building LangChain agents with MCP tools
- Framework interoperability patterns
- Tool calling with OpenAI function calling
- Multi-tool orchestration
- Agent-based task execution

## ğŸ“¦ What's Inside

âœ… **MCPTool Wrapper** - Bridge MCP to LangChain  
âœ… **LangChain Agent** - Use MCP tools in agents  
âœ… **Calculator + Weather** - Multiple MCP servers  
âœ… **OpenAI Integration** - GPT-4 function calling  
âœ… **Async Support** - Non-blocking operations  
âœ… **Real Examples** - Practical agent workflows

## ğŸš€ Quick Start

### 1. Get OpenAI API Key

Sign up at https://platform.openai.com/

### 2. Install Dependencies

```bash
uv sync
```

### 3. Configure Environment

```bash
cp .env.example .env
# Edit .env and add your API key
```

### 4. Run the Demo

```bash
uv run python main.py
```

## ğŸ§  Key Concepts

### Why Integrate MCP with LangChain?

**Benefits:**

- **Reusability**: Write MCP tools once, use everywhere
- **Standardization**: Common protocol across frameworks
- **Composability**: Mix MCP and native LangChain tools
- **Ecosystem**: Access MCP community tools

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LangChain Agent           â”‚
â”‚   (Orchestration)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”‚ MCPTool Wrapper
           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MCP Server(s)             â”‚
â”‚   (Tool Providers)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### MCPTool Wrapper

Converts MCP tools to LangChain `BaseTool`:

```python
class MCPTool(BaseTool):
    """LangChain tool wrapper for MCP tools."""

    name: str
    description: str
    mcp_client: Client
    mcp_tool_name: str

    def _run(self, **kwargs) -> str:
        # Execute MCP tool
        result = await self.mcp_client.call_tool(
            self.mcp_tool_name,
            kwargs
        )
        return str(result)
```

## ğŸ“š Example Workflows

### 1. Calculator Agent

```python
agent = create_agent_with_mcp_tools()

result = agent.run(
    "Calculate (15 + 27) * 3 and then divide by 6"
)
# Agent uses: add â†’ multiply â†’ divide
```

### 2. Weather Analysis

```python
result = agent.run(
    "What's the temperature difference between London and Paris?"
)
# Agent uses: get_weather(London) â†’ get_weather(Paris) â†’ subtract
```

### 3. Multi-Step Tasks

```python
result = agent.run(
    "Find cities where temperature is above 20Â°C: London, Paris, Berlin"
)
# Agent uses: get_weather multiple times â†’ compare results
```

## ğŸ”§ Advanced Usage

### Multiple MCP Servers

```python
toolkit = MCPToolkit(mcp_servers=[
    {"command": "python", "args": ["calculator_server.py"]},
    {"command": "python", "args": ["weather_server.py"]},
    {"command": "python", "args": ["database_server.py"]}
])

tools = await toolkit.get_tools()
# All tools from all servers available to agent
```

### Custom Tool Selection

```python
# Use only specific tools
selected_tools = [
    tool for tool in tools
    if tool.name in ["add", "subtract", "get_weather"]
]

agent = create_agent(llm, selected_tools)
```

## ğŸ“ Learning Notes

### LangChain Agent Types

1. **Zero-shot ReAct**: Best for MCP tools (reasons and acts)
2. **OpenAI Functions**: Native function calling
3. **Structured Chat**: For complex multi-tool scenarios

### Tool Calling Flow

```
1. User Query â†’ Agent
2. Agent â†’ LLM (What tools needed?)
3. LLM â†’ Agent (Use tool X with args Y)
4. Agent â†’ MCPTool â†’ MCP Server
5. MCP Server â†’ Tool Result
6. Result â†’ Agent â†’ LLM
7. LLM â†’ Final Answer
```

### Error Handling

```python
try:
    result = agent.run(query)
except ValueError as e:
    # Tool execution error
    print(f"Tool error: {e}")
except Exception as e:
    # Agent/LLM error
    print(f"Agent error: {e}")
```

## ğŸ“ Project Structure

```
demo-07-langchain-mcp-integration/
â”œâ”€â”€ .python-version      # Python 3.12
â”œâ”€â”€ .env                 # API keys
â”œâ”€â”€ .env.example         # Template
â”œâ”€â”€ .gitignore          # Excludes .env
â”œâ”€â”€ pyproject.toml      # Dependencies
â”œâ”€â”€ README.md           # This file
â””â”€â”€ main.py             # Integration demo
```

## ğŸ”§ Troubleshooting

### OpenAI API Error

Make sure your API key is valid and has credits.

### Tool Not Available

Check MCP server is running and tools are registered.

### Import Errors

```bash
# Make sure all dependencies installed
uv sync
```

## ğŸ’¡ Exercise Ideas

1. **RAG + MCP**: Combine LangChain RAG with MCP tools
2. **Custom Tools**: Create your own MCP tools for LangChain
3. **Multi-Agent**: Build agent that coordinates other agents
4. **Streaming**: Add streaming responses for real-time feedback

## ğŸ“š Next Steps

1. **Demo 08**: Build autonomous MCP agent
2. **Demo 09**: Multi-server coordination
3. Check LangChain docs for more agent patterns

## ğŸ”— Resources

- [LangChain Documentation](https://python.langchain.com/)
- [OpenAI Function Calling](https://platform.openai.com/docs/guides/function-calling)
- [MCP Specification](https://spec.modelcontextprotocol.io/)

---

**Happy Learning! ğŸš€**
